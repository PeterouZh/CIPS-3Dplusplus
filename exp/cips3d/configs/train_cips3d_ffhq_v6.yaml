root_obs: &root_obs s3://bucket-3690/ZhouPeng

network_pkl: &network_pkl
  FFHQ_N_freq4: "../bucket_3690/results/StyleSDF-exp/train_cips3d_ffhq_v4/train_r1024_r64_ks1-20220618_020428_188/ckptdir/resume"
  FFHQ_N_freq0: "../bucket_3690/results/StyleSDF-exp/train_cips3d_ffhq_v4/train_r1024_r64_ks1-20220618_023441_881/ckptdir/resume"


obs_inception_v3: &obs_inception_v3
  datapath_obs: 'keras/cache/torch/hub/checkpoints/weights-inception-2015-12-05-6726825d.pth'
  datapath: "~/.cache/torch/hub/checkpoints/weights-inception-2015-12-05-6726825d.pth"
  disable: false
  overwrite: false
  unzip: false


obs_ffhq_r1024: &obs_ffhq_r1024
  datapath_obs: 'keras/ffhq/images1024x1024_lmdb_1024/'
  datapath: "datasets/ffhq/images1024x1024_lmdb_1024/"
  disable: false
  overwrite: false
  unzip: false


G_cfg: &G_cfg
  register_modules:
    - "exp.cips3d.models.model_v6"
  name: "exp.cips3d.models.model_v6.Generator"
  enable_decoder: true
  freeze_renderer: false
  renderer_detach: false
  predict_rgb_residual: false
  scale_factor: 1
  renderer_cfg:
#    N_layers_renderer: 8
    N_layers_renderer: 2
    input_dim: 3
    hidden_dim: 256
#    style_dim: 256
    view_dim: 3
    with_sdf: true
    output_features : true
    triplane_cfg:
      N_planes: 3
      emb_dim: 32
      size: 128
      plane_mode: 'xy_xz_yz'
  mapping_renderer_cfg:
    z_dim: 256
    style_dim: 256
    N_layers: 3
  decoder_cfg:
    size_start: 4
    size_end: 1024
#    'style_dim': 512
    'in_channel': 256
    'channel_multiplier': 2
    'project_noise': False
    'upsample_list': [128, 256, 512, 1024]
#    'upsample_list': []
    'kernel_size': 1
    filter_size: 3
    filter_list: [256, 512, 1024]
  mapping_decoder_cfg:
#    z_dim: 256
    style_dim: 512
    lr_mul_mapping: 0.01
    N_layers: 5

G_symm_conv_cfg: &G_symm_conv_cfg
  base: G_cfg
  decoder_cfg:
    use_symm_conv: true
    'kernel_size': 3

G_kwargs: &G_kwargs
  cam_cfg:
    'img_size': 64
    'uniform': False
    'azim_range': 0.3
    'elev_range': 0.15
    'fov_ang': 6
    'dist_radius': 0.15
  nerf_cfg:
    N_samples: 24
    perturb: true
    static_viewdirs: false

_build_generator:
  G_cfg: *G_cfg
  G_kwargs: *G_kwargs

_build_generator_symm_conv:
  G_cfg: *G_symm_conv_cfg
  G_kwargs: *G_kwargs


D_cfg: &D_cfg
  register_modules:
    - "exp.cips3d.models.discriminator"
  name: "exp.cips3d.models.discriminator.D_StyleGAN_Progressive"
  input_size: 1024
  channel_multiplier: 2
  pretrained_size: null

D_renderer_cfg: &D_renderer_cfg
  register_modules:
    - "exp.cips3d.models.discriminator_pose"
  name: "exp.cips3d.models.discriminator_pose.D_VolumeRender_Progressive"
  input_size: 1024
  viewpoint_loss: true
  pretrained_size: null

train_base:
  root_obs: *root_obs
  obs_training_dataset: *obs_ffhq_r1024
#  obs_training_dataset: *obs_ffhq_r64
  obs_inception_v3: *obs_inception_v3
  G_cfg: *G_cfg
  G_kwargs: *G_kwargs
  D_cfg: *D_cfg
  D_renderer_cfg: *D_renderer_cfg
  # optims
  G_lr_render: 2.e-5
  G_lr_decoder: 0.002
  D_lr_render: 2.e-4
  D_lr_decoder: 0.002
  # args
  total_iters: 200000
  ema_start: 1000
  batch: 4
  chunk: 4
  expname: ffhq1024x1024
  size: 1024
  tl_finetune: false
  finetune_dir: "results/StyleSDF-exp/train_volume_render_ffhq/train_volume_render-20220325_102346_871/ckptdir/01"
  # train
  d_reg_every: 15
  g_reg_every: 5
#  d_reg_every: 16
#  g_reg_every: 4
  path_regularize: 2
  N_rays_forward: null
  N_rays_grad: null
  N_samples_forward: null
  fade_D: true
  fade_steps: 10000
  init_renderer: true
  init_iters: 10000
  init_renderer_ckpt: null
#  init_renderer_ckpt: "results/StyleSDF-exp/train_cips3d_ffhq/train_r64-20220331_224622_038/ckptdir/G_sdf_init.pth"
  grad_clip: 20.
  warmup_iters: -1
  num_workers: 0
  skip_eval: false
  # loss
  lambda_gp: 10.
  lambda_pose: 15.
  lambda_eikonal: 0.1
  lambda_min_surf: 0.05
  min_surf_beta: 100.
  # log
  log_txt_every: 10
  log_ckpt_every: 500
  log_N_row: 8
  log_N_col: 8
  # eval
  batch_gpu: 4
  N_gen_images_eval: 2048
  N_real_images_eval: 2048
  del_fid_real_images: true
  kid: false


train_r1024_r64_ks1:
  base: train_base
  obs_training_dataset: *obs_ffhq_r1024
  G_cfg:
    enable_decoder: true
#    freeze_renderer: true
#    renderer_detach: true
    freeze_renderer: false
    renderer_detach: false
    predict_rgb_residual: false
    renderer_cfg:
      N_layers_renderer: 2
    decoder_cfg:
      upsample_list: [128, 256, 512, 1024]
      kernel_size: 1
  G_kwargs:
    cam_cfg:
      img_size: 64
  D_cfg:
    pretrained_size: null
  D_renderer_cfg:
    pretrained_size: null
  init_renderer: true
  tl_finetune: false
#  tl_finetune: true
#  finetune_dir: "../bucket_3690/results/StyleSDF-exp/train_cips3d_ffhq_v3/train_r1024_r64_ks1-20220411_235145_682/ckptdir/resume"
  total_iters: 800000
  ema_start: 1000
  N_rays_forward: null
  N_rays_grad: null
  N_samples_forward: null
  eikonal_reg: true
  sdf_reg: true
#  eikonal_reg: false
#  sdf_reg: false
  g_reg_every: 5
#  g_reg_every: -1 # path_reg false
  batch_gpu: 4
  warmup_iters: 10000
  cam_img_size: 64
  gen_img_size: 1024 # train patch size
  data_img_size: 1024
#  sample_mode: 'patch'
